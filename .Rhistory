{
expandgrid2=function(x){
expand.grid(data.frame(x))}
checkmate::assertList(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
d=length(data)
if(sum(apply(sapply(data,dim),1,diff))!=0){
stop("Error: objects in data have different dimensions")}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
t=unique(sapply(data,nrow))
index=apply(cbind(1:2),1,function(x) seq(x,2*d,2))
trajectList=plyr::alply(expand.grid(1:n,1:n),1,function(i) plyr::alply(index,2,function(y) matrix(unlist(lapply(data,function(x) x[,unlist(i)])),nrow=t,ncol=2*d)[,y]))
if(parallel==FALSE){
return(matrix(sapply(trajectList,function(x) SimilarityMeasures::Frechet(x[[1]],x[[2]],testLeash=testLeash)),ncol=n,nrow=n))
} else {
cl=parallel::makeCluster(cl)
return(matrix(parallel::parSapply(cl,trajectList,function(x) SimilarityMeasures::Frechet(x[[1]],x[[2]])),ncol=n,nrow=n))
ntdist=matrix(parallel::parSapply(cl,trajectList,function(x) SimilarityMeasures::Frechet(x[[1]],x[[2]])),ncol=n,nrow=n)
parallel::stopCluster(cl)}
}
mFrechet=function(data,parallel=FALSE,cl=NULL,testLeash=-1)
{
checkmate::assertList(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
d=length(data)
if(sum(apply(sapply(data,dim),1,diff))!=0){
stop("Error: objects in data have different dimensions")}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
t=unique(sapply(data,nrow))
d= length(data)
# 3d matrix of data
data_array= array(unlist(data), dim=c(t,n,d))
#list of indices for upper rtriangular distances matrix
combs_lower_tri = combn(1:n, 2, simplify=FALSE)
if(parallel==FALSE){
#compute results of upper/lower triangle of distance matrix
lower_tri_res = sapply(combs_lower_tri,
function(x) SimilarityMeasures::Frechet(data_array[,x[1],],
data_array[,x[2],] ,
testLeash=testLeash))
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("data", "testLeash"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) SimilarityMeasures::Frechet(data_array[,x[1],],
data_array[,x[2],] ,
testLeash=testLeash))
parallel::stopCluster(cl)
}
#arrange results into distance matrix
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
Old = mFrechetOld(dist)
new = mFrechet(dist)
Old = mFrechetOld(dist)
new = mFrechet(dist)
dist = list()
for (i in (1:3)){
dist[[i]] = matrix(rnorm(16), nrow = 4, ncol = 4)
}
dist
mFrechetOld(dist)
mFrechet(dist)
Old = mFrechetOld(dist)
Old
new = mFrechet(dist)
new
install.packages("Rfast")
Occurences <- list()
X1 <- c(1,2,1,1)
X2 <- c(1,3,1,1)
X3 <- c(1,4,1,1)
Y1 <- c(1,2,1,1)
Y2 <- c(1,3,1,1)
Y3 <- c(1,4,1,1)
Z1 <- c(1,2,1,1)
Z2 <- c(1,3,1,1)
Z3 <- c(1,4,1,1)
Occurences[[1]] <- cbind(X1, X2, X3)
Occurences[[2]] <- cbind(Y1, Y2, Y3)
Occurences[[3]] <- cbind(Z1, Z2, Z3)
Occurences
dim(1)
?dim
data = matrix(1:16, ncol = 4, nrow = 4)
Maxs= Rfast::colMaxs(data)
Maxs
data
Rfast::colMaxs(data)
?RFasr::colMaxs
?RFast::colMaxs
?Rfast::colMaxs
Rfast::colMaxs(data, value =TRUE)
?combn
n=4
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE)
lower_tri_res = sapply(combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) )
lower_tri_res
Maxs
Maxs= Rfast::colMaxs(data, value =TRUE)
Maxs
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) )
lower_tri_res
mglobMax3=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertMatrix(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
if(parallel==FALSE){
Maxs= Rfast::colMaxs(data, value =TRUE) # returns maximum per column
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("Maxs"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
parallel::stopCluster(cl)
}
#format results
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
mglobMax3(data)
data
ncol(data)
mglobMax3=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertMatrix(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=ncol(data)
if(parallel==FALSE){
Maxs= Rfast::colMaxs(data, value =TRUE) # returns maximum per column
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("Maxs"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
parallel::stopCluster(cl)
}
#format results
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
mglobMax3(data)
data
mglobMax3(data, parallel = TRUE, cl = 3)
3!=2
positionlist[[1]] = matrix(1:16, nrow = 4, ncols= 4)
positionlist[[2]] = matrix(101:116, nrow = 4, ncols= 4)
positionlist[[1]] = matrix(1:16, nrow = 4, ncol= 4)
positionlist[[2]] = matrix(101:116, nrow = 4, ncol= 4)
positionlist=list()
positionlist[[1]] = matrix(1:16, nrow = 4, ncol= 4)
positionlist[[2]] = matrix(101:116, nrow = 4, ncol= 4)
mglobMax3(positionlist)
mglobMax2(positionlist)
mglobMax2=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertList(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
d=length(data)
if(d != 2){stop("Error: objects in data do not have 2 dimensions")}
if(sum(apply(sapply(data,dim),1,diff))!=0){
stop("Error: objects in data have different dimensions")}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
if(parallel==FALSE){
return(abs(mglobMax3(data[[1]])-mglobMax3(data[[2]])))
} else {
return(abs(mglobMax3(data[[1]], parallel = parallel, cl = cl)-mglobMax3(data[[2]], parallel = parallel, cl = cl )))
}
}
mglobMax2(positionlist)
positionlist[[1]]
positionlist[[2]]
mglobMax2(positionlist, parallel = TRUE, cl = 3)
mglobMax3(positionlist[[2]], parallel = TRUE, cl = 3)
mglobMax3(positionlist[[1]], parallel = TRUE, cl = 3)
positionlist[[3]] = matrix(101:116, nrow = 4, ncol= 4)
mglobMax3(positionlist, parallel = TRUE, cl = 3)
mglobMax2(positionlist, parallel = TRUE, cl = 3)
#' Global Minimum distance between multivariate functions
#'
#' Computes the Global Minimum distance for all pairs of \eqn{m}-dimensional functions. For a single pair of functions,
#' the present R function returns the minimum euclidean distance between the function values at equal time points.
#'
#' @param data a matrix that stores a dimension of the set of functions, such that columns are individuals (\eqn{n}) and rows are discrete-time points (\eqn{t}). Functions' values should be of the same time points.
#' @param parallel logical value indicating whether computations should be parallelized. Default is FALSE. If TRUE, parallelization is conducted with \href{https://www.rdocumentation.org/packages/parallel}{parallel} package.
#' @param cl a cluster object created by \href{https://www.rdocumentation.org/packages/parallel}{parallel}. Default is NULL.
#' @return Returns a square and symmetric \eqn{n x n} matrix of \eqn{m}-dimensional global minimum distances.
#' @details For each pair of functions f and g, the present R function computes: \eqn{min t [Euclidean_Distance(f(t), g(t))]}
#' @seealso See \code{\link[parallel:makeCluster]{makeCluster}}, \code{\link[parallel:clusterExport]{clusterExport}}, \code{\link[parallel:stopCluster]{stopCluster}}, \code{\link[parallel:parApply]{parApply}} and \code{\link[parallel:parLapply]{parLapply}} from  \href{https://www.rdocumentation.org/packages/parallel}{parallel}, and \code{\link[proxy:dist]{dist}} from \href{https://cran.r-project.org/web/packages/proxy/index.html}{proxy}
#' @examples
#' ## 2-dimensional functions
#'
#' x = replicate(4, rnorm(100, 0, 3))
#' y = replicate(4, rnorm(100, 3, 1))
#' data = list(x, y)
#' mglobmin(data, parallel = FALSE, cl = NULL)
#'
#' ## 3-dimensional functions
#'
#' z = replicate(4, rpois(100, 2))
#' data = list(x, y, z)
#' mglobmin(data, parallel = FALSE, cl = NULL)
#'
#' @export
mglobMin3=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertMatrix(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=ncol(data)
if(parallel==FALSE){
Mins= Rfast::colMins(data, value =TRUE) # returns minimum per column
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,function(x) abs(Mins[x[[1]]]-Mins[x[[2]]]) ) # compute results for upper triangular distance matrix
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("Mins"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) abs(Mins[x[[1]]]-Mins[x[[2]]]) ) # compute results for upper triangular distance matrix
parallel::stopCluster(cl)
}
#format results
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
#' @export
mglobMin2=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertList(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
d=length(data)
if(d != 2){stop("Error: objects in data do not have 2 dimensions")}
if(sum(apply(sapply(data,dim),1,diff))!=0){
stop("Error: objects in data have different dimensions")}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
if(parallel==FALSE){
return(abs(mglobMin3(data[[1]])-mglobMin3(data[[2]])))
} else {
return(abs(mglobMin3(data[[1]], parallel = parallel, cl = cl)-mglobMin3(data[[2]], parallel = parallel, cl = cl )))
}
}
mglobMin3(data)
data
positionlist2[[1]]=positionlist[[1]]
positionlist2=list()
positionlist2[[1]]=positionlist[[1]]
positionlist2[[2]]=positionlist[[2]]
mglobMin2(positionlist2)
load("U:/classiMultiFunc/Application/CV Results/Results_new_Frechet_deriv1")
load("U:/classiMultiFunc/Application/CV Results/Results_new_Frechet_deriv1.Rdata")
View(result_list)
result_list[[1]]
f <- function(x){ 1/x^2}
curve(f)
require(distr)
install.packages(distr)
require(distr)
install.packages("distr")
require(distr)
F = AbscontDistribution(d = function(x){ 1/x^2})
F = AbscontDistribution(d = function(x){ 1/x^2}, from = -Inf, to = +Inf)
?AbscontDistribution
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
load("./Code/Data_prep/total_data.Rdata")
#install.packages("corrplot")
library("corrplot")
library("dplyr")
df$Target_def = as.numeric(df$Target_def)
corr_plot_data = df%>% select_if(is.numeric)
M = cor(corr_plot_data)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
?cor
M = cor(corr_plot_data, use = "pairwise.complete.obs")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
M = cor(corr_plot_data, use = "pairwise.complete.obs", method="spearman")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
df$Target_def = as.numeric(df$Target_def)
corr_plot_data = df%>% select_if(is.numeric)
M = cor(corr_plot_data, use = "pairwise.complete.obs", method="pearson")
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
jpeg('Correlogram.jpg')
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dev.off()
?jpeg
jpeg('Correlogram.jpg',width = 1500, height = 1500)
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dev.off()
jpeg('Correlogram.jpg',width = 1000, height = 1000)
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dev.off()
jpeg('Correlogram.jpg',width = 800, height = 800)
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dev.off()
jpeg('Correlogram.jpg',width = 900, height = 900)
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dev.off()
jpeg('Correlogram.jpg',width = 600, height = 600)
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
sig.level = 0.01,
insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
dev.off()
?corrplot
corrplot(M, method="color", col=col(200),
type="upper",
#order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
#sig.level = 0.01,
#insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
?corrplot
df$Target_def = as.numeric(df$Target_def)
df$Target_def
