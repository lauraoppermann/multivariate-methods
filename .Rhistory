Occurences[[3]] <- cbind(Z1, Z2, Z3)
Occurences
dim(1)
?dim
data = matrix(1:16, ncol = 4, nrow = 4)
Maxs= Rfast::colMaxs(data)
Maxs
data
Rfast::colMaxs(data)
?RFasr::colMaxs
?RFast::colMaxs
?Rfast::colMaxs
Rfast::colMaxs(data, value =TRUE)
?combn
n=4
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE)
lower_tri_res = sapply(combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) )
lower_tri_res
Maxs
Maxs= Rfast::colMaxs(data, value =TRUE)
Maxs
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) )
lower_tri_res
mglobMax3=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertMatrix(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
if(parallel==FALSE){
Maxs= Rfast::colMaxs(data, value =TRUE) # returns maximum per column
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("Maxs"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
parallel::stopCluster(cl)
}
#format results
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
mglobMax3(data)
data
ncol(data)
mglobMax3=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertMatrix(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=ncol(data)
if(parallel==FALSE){
Maxs= Rfast::colMaxs(data, value =TRUE) # returns maximum per column
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("Maxs"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) abs(Maxs[x[[1]]]-Maxs[x[[2]]]) ) # compute results for upper triangular distance matrix
parallel::stopCluster(cl)
}
#format results
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
mglobMax3(data)
data
mglobMax3(data, parallel = TRUE, cl = 3)
3!=2
positionlist[[1]] = matrix(1:16, nrow = 4, ncols= 4)
positionlist[[2]] = matrix(101:116, nrow = 4, ncols= 4)
positionlist[[1]] = matrix(1:16, nrow = 4, ncol= 4)
positionlist[[2]] = matrix(101:116, nrow = 4, ncol= 4)
positionlist=list()
positionlist[[1]] = matrix(1:16, nrow = 4, ncol= 4)
positionlist[[2]] = matrix(101:116, nrow = 4, ncol= 4)
mglobMax3(positionlist)
mglobMax2(positionlist)
mglobMax2=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertList(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
d=length(data)
if(d != 2){stop("Error: objects in data do not have 2 dimensions")}
if(sum(apply(sapply(data,dim),1,diff))!=0){
stop("Error: objects in data have different dimensions")}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
if(parallel==FALSE){
return(abs(mglobMax3(data[[1]])-mglobMax3(data[[2]])))
} else {
return(abs(mglobMax3(data[[1]], parallel = parallel, cl = cl)-mglobMax3(data[[2]], parallel = parallel, cl = cl )))
}
}
mglobMax2(positionlist)
positionlist[[1]]
positionlist[[2]]
mglobMax2(positionlist, parallel = TRUE, cl = 3)
mglobMax3(positionlist[[2]], parallel = TRUE, cl = 3)
mglobMax3(positionlist[[1]], parallel = TRUE, cl = 3)
positionlist[[3]] = matrix(101:116, nrow = 4, ncol= 4)
mglobMax3(positionlist, parallel = TRUE, cl = 3)
mglobMax2(positionlist, parallel = TRUE, cl = 3)
#' Global Minimum distance between multivariate functions
#'
#' Computes the Global Minimum distance for all pairs of \eqn{m}-dimensional functions. For a single pair of functions,
#' the present R function returns the minimum euclidean distance between the function values at equal time points.
#'
#' @param data a matrix that stores a dimension of the set of functions, such that columns are individuals (\eqn{n}) and rows are discrete-time points (\eqn{t}). Functions' values should be of the same time points.
#' @param parallel logical value indicating whether computations should be parallelized. Default is FALSE. If TRUE, parallelization is conducted with \href{https://www.rdocumentation.org/packages/parallel}{parallel} package.
#' @param cl a cluster object created by \href{https://www.rdocumentation.org/packages/parallel}{parallel}. Default is NULL.
#' @return Returns a square and symmetric \eqn{n x n} matrix of \eqn{m}-dimensional global minimum distances.
#' @details For each pair of functions f and g, the present R function computes: \eqn{min t [Euclidean_Distance(f(t), g(t))]}
#' @seealso See \code{\link[parallel:makeCluster]{makeCluster}}, \code{\link[parallel:clusterExport]{clusterExport}}, \code{\link[parallel:stopCluster]{stopCluster}}, \code{\link[parallel:parApply]{parApply}} and \code{\link[parallel:parLapply]{parLapply}} from  \href{https://www.rdocumentation.org/packages/parallel}{parallel}, and \code{\link[proxy:dist]{dist}} from \href{https://cran.r-project.org/web/packages/proxy/index.html}{proxy}
#' @examples
#' ## 2-dimensional functions
#'
#' x = replicate(4, rnorm(100, 0, 3))
#' y = replicate(4, rnorm(100, 3, 1))
#' data = list(x, y)
#' mglobmin(data, parallel = FALSE, cl = NULL)
#'
#' ## 3-dimensional functions
#'
#' z = replicate(4, rpois(100, 2))
#' data = list(x, y, z)
#' mglobmin(data, parallel = FALSE, cl = NULL)
#'
#' @export
mglobMin3=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertMatrix(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=ncol(data)
if(parallel==FALSE){
Mins= Rfast::colMins(data, value =TRUE) # returns minimum per column
combs_lower_tri = utils::combn(1:n, 2, simplify=FALSE) #combinations for indexes of upper triangular matrix
lower_tri_res = sapply(combs_lower_tri,function(x) abs(Mins[x[[1]]]-Mins[x[[2]]]) ) # compute results for upper triangular distance matrix
} else {
cl=parallel::makeCluster(cl)
parallel::clusterExport(cl,list("Mins"))
#compute results of upper/lower triangle of distance matrix
lower_tri_res = parallel::parSapply(cl,
combs_lower_tri,
function(x) abs(Mins[x[[1]]]-Mins[x[[2]]]) ) # compute results for upper triangular distance matrix
parallel::stopCluster(cl)
}
#format results
result_matrix = matrix(NA, nrow = n, ncol = n)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
result_matrix = t(result_matrix)
result_matrix[lower.tri(result_matrix)] = lower_tri_res
diag(result_matrix)= rep(0, n)
return(result_matrix)
}
#' @export
mglobMin2=function(data,parallel=FALSE,cl=NULL)
{
checkmate::assertList(data)
checkmate::assertLogical(parallel)
if(!is.null(cl)){
if(!isTRUE(parallel)){
stop("Error: parallel should be TRUE")}
checkmate::assertNumeric(cl,lower=1)}
d=length(data)
if(d != 2){stop("Error: objects in data do not have 2 dimensions")}
if(sum(apply(sapply(data,dim),1,diff))!=0){
stop("Error: objects in data have different dimensions")}
if(sum(sapply(data,function(x)sum(is.na(x))))!=0){
warning("data have missing values; some distances cannot be computed.")}
n=unique(sapply(data,ncol))
if(parallel==FALSE){
return(abs(mglobMin3(data[[1]])-mglobMin3(data[[2]])))
} else {
return(abs(mglobMin3(data[[1]], parallel = parallel, cl = cl)-mglobMin3(data[[2]], parallel = parallel, cl = cl )))
}
}
mglobMin3(data)
data
positionlist2[[1]]=positionlist[[1]]
positionlist2=list()
positionlist2[[1]]=positionlist[[1]]
positionlist2[[2]]=positionlist[[2]]
mglobMin2(positionlist2)
load("U:/classiMultiFunc/Application/CV Results/Results_new_Frechet_deriv1")
load("U:/classiMultiFunc/Application/CV Results/Results_new_Frechet_deriv1.Rdata")
View(result_list)
result_list[[1]]
f <- function(x){ 1/x^2}
curve(f)
require(distr)
install.packages(distr)
require(distr)
install.packages("distr")
require(distr)
F = AbscontDistribution(d = function(x){ 1/x^2})
F = AbscontDistribution(d = function(x){ 1/x^2}, from = -Inf, to = +Inf)
?AbscontDistribution
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
library("dplyr")
library("readr")
install.packages("tidyverse")
install.packages("tidyverse")
library("readr")
#library("readr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
readr::read_csv("./Data/data.csv")
data = readr::read_csv("./Data/data.csv")
View(data)
data2 = read.csv("./Data/data.csv")
View(data2)
View(data)
str(data2)
View(data)
str(data)
rm(list="data2")
rm(list="data")
data2 = read.csv("./Data/data.csv")
View(data2)
str(data2)
View(data2)
View(data2)
library("lubridate")
date_var_names = c("Date.of.Birth","DisbursalDate")
date_time_names = c("AVERAGE.ACCT.AGE", "CREDIT.HISTORY.LENGTH" )
?sapply
as.Date(data$AVERAGE.ACCT.AGE)
lubridate::as.Date(data$AVERAGE.ACCT.AGE)
lubridate::as.date(data$AVERAGE.ACCT.AGE)
lubridate::dmy(data$AVERAGE.ACCT.AGE)
lubridate::dmy(data[,"AVERAGE.ACCT.AGE"])
lubridate::dmy(data[1,"AVERAGE.ACCT.AGE"])
lubridate::dmy(Data$AVERAGE.ACCT.AGE)
data = read.csv("./Data/data.csv")
rm(list="data2")
data$AVERAGE.ACCT.AGE
lubridate::dmy(data$Date.of.Birth)
lapply(date_var_names, function(x){lubridate::dmy(data$x)})
date_var_names = list("Date.of.Birth","DisbursalDate")
lapply(date_var_names, function(x){lubridate::dmy(data$x)})
date_var_names = list("Date.of.Birth","DisbursalDate")
lapply(date_var_names, function(x){lubridate::dmy(data[,x])})
for (name in date_var_names){print name}
for (name in date_var_names){print(name)}
date_var_names = list("Date.of.Birth","DisbursalDate")
for (name in date_var_names){data[, name]= lubridate::dmy(data[,name])}
View(data)
str(data)
strsplit(c("test1 et test2","test1 et test2"), split= "et")
?strsplit
as.matrix(strsplit(c("test1 et test2","test1 et test2"), split= "et"))
?paste0
for (name in date_time_names){data[, paste0(name, "Years")]= strsplit(data[,name], "yrs")}
test= "test"
paste0(test, "Years")
View(data)
for (name in date_time_names){
data[,name] = as.character(data[,name])
data[, paste0(name, "Years")]= strsplit(data[,name], "yrs")}
library("stringr")
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, "yrs",1 )
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, "yrs",2 )
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs","mon"), 3)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, "yrs",2)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, "mon",2)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, " ", 2)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs","mon"))
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs","_","mon"), 4)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs","_","mon"), 5)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs","_","mon"), 2)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs","_","mon"), 1)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs"," ","mon"), 5)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("yrs"," ","mon"), 4)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c("mon"), 1)
stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c(" "), 2)
test = stringr::str_split_fixed(data$AVERAGE.ACCT.AGE, c(" "), 2)
str_replace_all(test, "yrs", "")
str_replace_all(test[,1], "yrs", "")
for (name in date_time_names){
data[,name] = as.character(data[,name])
splitted = stringr::str_split_fixed(data$AVERAGE.ACCT.AGE,
" ",
2)
data[, paste0(name, "Years")] = str_replace_all(splitted[,1], "yrs", "")
data[, paste0(name, "Months")] = str_replace_all(splitted[,2], "mon", "")
}
View(data)
for (name in date_time_names){
data[,name] = as.character(data[,name])
splitted = stringr::str_split_fixed(data$AVERAGE.ACCT.AGE,
" ",
2)
Years = as.numeric(stringr::str_replace_all(splitted[,1],
"yrs",
"")
)
Months = as.numeric(stringr::str_replace_all(splitted[,2],
"mon",
"")
)
data[,name] = Years + Months
}
View(data)
rm(list=ls())
library("lubridate")
library("stringr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
data = read.csv("./Data/data.csv")
### Change dates to numerics
# formats "DD-MM-YY" to Number of days since 01.01.1900
date_var_names = list("Date.of.Birth","DisbursalDate")
for (name in date_var_names){data[, name]= lubridate::dmy(data[,name])}
# formats "XX yrs XX mon" to Number of months in total
date_time_names = c("AVERAGE.ACCT.AGE", "CREDIT.HISTORY.LENGTH" )
for (name in date_time_names){
data[,name] = as.character(data[,name])
splitted = stringr::str_split_fixed(data$AVERAGE.ACCT.AGE,
" ",
2)
Years = as.numeric(stringr::str_replace_all(splitted[,1],
"yrs",
"")
)
Months = as.numeric(stringr::str_replace_all(splitted[,2],
"mon",
"")
)
data[,name] = Years + (Months/12)
}
View(data)
get_year_months = function(vec){
vec = as.character(vec)
splitted = stringr::str_split_fixed(vec,
" ",
2)
Years = as.numeric(stringr::str_replace_all(splitted[,1],
"yrs",
"")
)
Months = as.numeric(stringr::str_replace_all(splitted[,2],
"mon",
"")
)
vec = Years + (Months/12)
}
get_year_months(data$AVERAGE.ACCT.AGE)
a = get_year_months(data$AVERAGE.ACCT.AGE)
library("lubridate")
library("stringr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
data = read.csv("./Data/data.csv")
# formats "DD-MM-YY" to Number of days since 01.01.1900
date_var_names = list("Date.of.Birth","DisbursalDate")
for (name in date_var_names){data[, name]= lubridate::dmy(data[,name])}
get_year_months = function(vec){
vec = as.character(vec)
splitted = stringr::str_split_fixed(vec,
" ",
2)
Years = as.numeric(stringr::str_replace_all(splitted[,1],
"yrs",
"")
)
Months = as.numeric(stringr::str_replace_all(splitted[,2],
"mon",
"")
)
vec = Years + (Months/12)
}
a = get_year_months(data$CREDIT.HISTORY.LENGTH)
get_year_months = function(vec){
vec = as.character(vec)
splitted = stringr::str_split_fixed(vec,
" ",
2)
Years = as.numeric(stringr::str_replace_all(splitted[,1],
"yrs",
"")
)
Months = as.numeric(stringr::str_replace_all(splitted[,2],
"mon",
"")
)
return(Years + (Months/12))
}
lapply(data[,date_time_names], get_year_months)
sapply(data[,date_time_names], get_year_months)
data[,date_time_names] = sapply(data[,date_time_names], get_year_months)
View(data)
rm(list=ls())
library("lubridate")
library("stringr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
data = read.csv("./Data/data.csv")
### Change dates and times to numerics
# formats "DD-MM-YY" to Number of days since 01.01.1900
date_var_names = list("Date.of.Birth","DisbursalDate")
data[,date_var_names] = sapply(data[,date_var_names], lubridate::dmy)
as.numeric(data$Date.of.Birth)
data$Date.of.Birth
year(data$Date.of.Birth)
rm(list=ls()
)
library("lubridate")
library("stringr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
data = read.csv("./Data/data.csv")
### Change dates and times to numeri
date_var_names = list("Date.of.Birth","DisbursalDate")
for (name in date_var_names){data[, name]= lubridate::dmy(data[,name])}
as.numeric(data$Date.of.Birth)
year(data$Date.of.Birth)
rm(list=ls())
library("lubridate")
library("stringr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
data = read.csv("./Data/data.csv")
### Change dates and times to numerics
# formats "DD-MM-YY" to Number of days since 01.01.1900
date_var_names = list("Date.of.Birth","DisbursalDate")
#function to change cut-off year. Lubridate was changing 68 to 2068 no 1968
cut_off_year = function(x, year=1910){
m <- year(x) %% 100
year(x) <- ifelse(m > year %% 100, 1900+m, 2000+m)
x
}
for (name in date_var_names){data[, name]= cut_off_year(lubridate::dmy(data[,name])
)
}
as.numeric(data$Date.of.Birth)
year(data$Date.of.Birth)
as.numeric(data$Date.of.Birth)
year(data$Date.of.Birth)
rm(list=ls())
library("lubridate")
library("stringr")
setwd("C:/Users/felix/Documents/GitHub/multivariate-methods")
data = read.csv("./Data/data.csv")
### Change dates and times to numerics
# formats "DD-MM-YY" to Number of days since 01.01.1900
date_var_names = list("Date.of.Birth","DisbursalDate")
#function to change cut-off year. Lubridate was changing 68 to 2068 no 1968
cut_off_year = function(x, year=1910){
m <- year(x) %% 100
year(x) <- ifelse(m > year %% 100, 1900+m, 2000+m)
x
}
for (name in date_var_names){
data[, name] = as.numeric(
cut_off_year(
lubridate::dmy(data[,name])
)
)
}
# formats "XX yrs XX mon" to Number of Years in total
date_time_names = c("AVERAGE.ACCT.AGE", "CREDIT.HISTORY.LENGTH" )
get_year_months = function(vec){
vec = as.character(vec)
splitted = stringr::str_split_fixed(vec,
" ",
2)
Years = as.numeric(stringr::str_replace_all(splitted[,1],
"yrs",
"")
)
Months = as.numeric(stringr::str_replace_all(splitted[,2],
"mon",
"")
)
return(Years + (Months/12))
}
data[,date_time_names] = sapply(data[,date_time_names], get_year_months)
View(data)
